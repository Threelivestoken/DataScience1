{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3fcf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f7bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup = BeautifulSoup(\"<p>Some<b>bad<i>HTML\")\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e412d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question is: What is the average amount of words linked on a wiki page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "909dc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focus on creating a list of the urls, url is the list with urls\n",
    "alp=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\"]\n",
    "let=[\"B\",\"C\",\"D\",\"F\",\"G\",\"H\",\"J\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "vow=[\"a\",\"e\",\"i\",\"o\",\"u\"]\n",
    "page=[]\n",
    "\n",
    "#makes pages that are a combination of let and vow\n",
    "for first in range(len(vow)):\n",
    "    for second in range(len(let)):\n",
    "        page.append(let[second]+vow[first-1])\n",
    "\n",
    "#this is your list of pages\n",
    "#page=['Ba', 'Ca', 'Da', 'Fa', 'Ga', 'Ha', 'Ja', 'Ka', 'La', 'Ma', 'Na', 'Pa', 'Qa', 'Ra', 'Sa', 'Ta', 'Va', 'Wa', 'Xa', 'Ya', 'Za', 'Be', 'Ce', 'De', 'Fe', 'Ge', 'He', 'Je', 'Ke', 'Le', 'Me', 'Ne', 'Pe', 'Qe', 'Re', 'Se', 'Te', 'Ve', 'We', 'Xe', 'Ye', 'Ze', 'Bi', 'Ci', 'Di', 'Fi', 'Gi', 'Hi', 'Ji', 'Ki', 'Li', 'Mi', 'Ni', 'Pi', 'Qi', 'Ri', 'Si', 'Ti', 'Vi', 'Wi', 'Xi', 'Yi', 'Zi', 'Bo', 'Co', 'Do', 'Fo', 'Go', 'Ho', 'Jo', 'Ko', 'Lo', 'Mo', 'No', 'Po', 'Qo', 'Ro', 'So', 'To', 'Vo', 'Wo', 'Xo', 'Yo', 'Zo', 'Bu', 'Cu', 'Du', 'Fu', 'Gu', 'Hu', 'Ju', 'Ku', 'Lu', 'Mu', 'Nu', 'Pu', 'Qu', 'Ru', 'Su', 'Tu', 'Vu', 'Wu', 'Xu', 'Yu', 'Zu']\n",
    "\n",
    "\n",
    "#Makes the pages into a list of urls\n",
    "url=[]\n",
    "for taco in range(len(page)):\n",
    "    url.append(\"https://en.wikipedia.org/wiki/\"+page[taco])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5678ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "response=[]\n",
    "url\n",
    "for taco in range(len(url)):\n",
    "    response.append(requests.get(url[taco]))\n",
    "\n",
    "\n",
    "    \n",
    "#for taco in range(len(response)):\n",
    "#    soup = BeautifulSoup(response[taco].text, 'html.parser')\n",
    "#    links = soup.find_all('a')\n",
    "#    total_links=links\n",
    "#for taco in range(len(links)):\n",
    "#    total_links[taco] = len(links[taco])\n",
    "\n",
    "\n",
    "#link_count_all=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "#link_count=0\n",
    "#for lego in range(len(link_count_all)):\n",
    "#    for taco in links[lego]:\n",
    "#        href = taco.get('href')\n",
    "#        if href and href.startswith('/wiki/'):\n",
    "#            link_count=link_count+1\n",
    "#    link_count_all[lego]=link_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55760f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for taco in range(len(response)):\n",
    "#    soup = BeautifulSoup(response[taco].text, 'html.parser')\n",
    "#    links = soup.find_all('a')\n",
    "#    total_links=links\n",
    "#for taco in range(len(links)):\n",
    "#    total_links[taco] = len(links[taco])\n",
    "\n",
    "#setup for lists\n",
    "soup=[]\n",
    "links=[]\n",
    "\n",
    "#get links as a list\n",
    "for taco in range(len(url)):\n",
    "    soup.append(BeautifulSoup(response[taco].text, 'html.parser'))\n",
    "for taco in range(len(url)):\n",
    "    links.append(soup[taco].find_all('a'))\n",
    "    \n",
    "#Gives you the totalwikipageslinked\n",
    "link_count=0\n",
    "wiki_tot=[]\n",
    "for salsa in range(len(url)):\n",
    "    link_count=0\n",
    "    for taco in links[salsa]:\n",
    "        href = taco.get('href')\n",
    "        if href and href.startswith('/wiki/'):\n",
    "            link_count=link_count+1\n",
    "    wiki_tot.append(link_count)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#just gives you the total links, not just other wiki pages linked\n",
    "total_links=[]\n",
    "for taco in range(len(url)):\n",
    "    total_links.append(len(links[taco]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5aaf294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives you the average amount of links on a wikipedia page based on certain pages\n",
    "avg_link=sum(wiki_tot)/len(wiki_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0e11ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.56190476190476"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d3523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983b1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    \"url\":url,\n",
    "    \"wiki_total\":wiki_tot\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=data,x='url',y=\"wiki_url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6777e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#foundation of it\n",
    "url = 'https://en.wikipedia.org/wiki/Ba'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "links = soup.find_all('a')\n",
    "link_count=0\n",
    "for taco in links:\n",
    "    href = taco.get('href')\n",
    "    if href and href.startswith('/wiki/'):\n",
    "        link_count=link_count+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
